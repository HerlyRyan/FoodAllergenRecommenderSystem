# -*- coding: utf-8 -*-
"""sistem-rekomendasi-makanan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XuoUkjsIwJ-tna1tA-ErO4TPgyiShH4q

### Import Library for Dependency
"""

# Commented out IPython magic to ensure Python compatibility.
# Import kaggle for get dataset from kaggle
import kagglehub

# Import Library
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
import seaborn as sns
import os, shutil
from collections import Counter

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""### Exploratory Dataset

#### Data Loading
"""

source = kagglehub.dataset_download("uom190346a/food-ingredients-and-allergens")

# Define the destination path
destination_path = 'dataset'

# Move the dataset to the destination directory
shutil.copytree(source, destination_path)

print(f"Dataset downloaded and moved to {destination_path}")

"""#### Data Reading"""

df = pd.read_csv("/content/dataset/food_ingredients_and_allergens.csv")
df.head(5)

# Return information of dataframe
df.info()

# Check the null column
df.isnull().sum()

# Check the duplicated column
df.duplicated().sum()

df.describe(include="all")

"""#### Data Cleaning"""

# Fill the missing value using mode because dtype is object
for col in df.columns:
  if df[col].isnull().any():
    mode = df[col].mode()[0]
    df[col].fillna(mode, inplace=True)

# Check missing value again
df.isnull().sum()

# Delete duplicated data
df.drop_duplicates(inplace=True)
df.duplicated().sum()

# Check the total data
df.info()

"""#### Exploratory Data Analysis (EDA)"""

# Get allergens series
allergen_series = df["Allergens"].apply(lambda x: [i.strip() for i in x.split(",")])

# Convert the list of series data to flatten (2D to 1D)
allergen_flat = [allergen for sublist in allergen_series for allergen in sublist]

# Count the frequency each allergen
allergen_freq = Counter(allergen_flat)

# Convert to DataFrame
allergen_df = pd.DataFrame.from_dict(allergen_freq, orient='index', columns=['Frequency']).reset_index()
allergen_df.columns = ['Allergen', 'Frequency']
allergen_df

# Return the unique data from column Allergens
print("Total Allergens: ", len(allergen_df['Allergen'].unique()))
print("Allergens: ", allergen_df['Allergen'].unique())

plt.figure(figsize=[8, 5])
sns.barplot(data=allergen_df, x='Allergen', y='Frequency', palette='viridis')
plt.title('Frequency Allergen in Dataset')
plt.xlabel('Allergen')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Modelling using Content Based Filtering"""

# Inisialization using TfidfVectorizer
tf = TfidfVectorizer()

# Count Allergens from dataframe
tf.fit(df['Allergens'])

# Mapping array from index feature integer to name feature
tf.get_feature_names_out()

# Fit_transform to matrix
tfidf_matrix = tf.fit_transform(df['Allergens'])

# Return shape of tfidf_matrix
tfidf_matrix.shape

# Change vector to matrix using todense() function
tfidf_matrix.todense()

# Create dataframe to see tfidf_matrix
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=df['Food Product']
).sample(10, axis=1).sample(10, axis=0)

# Calculate cosine similarity on matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Create dataframe from variable cosine_sim
cosine_sim_df = pd.DataFrame(cosine_sim, index=df['Food Product'], columns=df['Food Product'])
print('Shape:', cosine_sim_df.shape)

# Return similarity matrix
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

def food_avoids(food_product, similarity_data=cosine_sim_df, items=df[['Food Product', 'Allergens']], k=10):
    """
    Avoids food products based on similarity of allergens.

    Args:
        food_product (str): The name of the food product to find avoids for.
        similarity_data (pd.DataFrame): The cosine similarity DataFrame.
        items (pd.DataFrame): DataFrame containing 'Food Product' and 'Allergens' columns.
        k (int): The number of avoids to return.

    Returns:
        pd.DataFrame: A DataFrame containing the top k avoids food products.
    """
    # Get the index of the food product in the items DataFrame
    try:
        index_val = items[items['Food Product'] == food_product].index[0]
    except IndexError:
        print(f"Food product '{food_product}' not found in the dataset.")
        return pd.DataFrame()  # Return an empty DataFrame if not found

    # Get the similarities for the given food product
    similarities = similarity_data.iloc[index_val].to_numpy()

    # Get the indices of the most similar items using argpartition
    # (excluding the item itself)
    index = similarities.argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(items.iloc[index_val]['Food Product'], errors='ignore')  # Drop the current item

    # Return the top k avoids
    # Create DataFrame with 'Food Product' as column
    avoids_df = pd.DataFrame(closest, columns=['Food Product'])
    # Merge on 'Food Product' column
    return avoids_df.merge(items, on='Food Product').head(k)

"""### Testing"""

# Return food product to test
food_product = 'Mushroom Risotto'
df[df['Food Product'].eq(food_product)].head(1)

# Return result from avoid food product based on allergen
food_product = 'Mushroom Risotto'
food_avoids = food_avoids(food_product)
food_avoids