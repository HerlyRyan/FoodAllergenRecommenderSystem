# -*- coding: utf-8 -*-
"""sistem-rekomendasi-makanan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XuoUkjsIwJ-tna1tA-ErO4TPgyiShH4q

### Import Library for Dependency

Dalam tahap ini melakukan import library untuk keperluan development model
"""

# Commented out IPython magic to ensure Python compatibility.
# Import kaggle for get dataset from kaggle
import kagglehub

# Import Library
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
import seaborn as sns
import os, shutil
from collections import Counter

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""### Exploratory Dataset

Melakukan eksplorasi data sesuai dengan pemahaman dan tujuan bisnis

#### Data Loading

mengambil dataset dari kaggle dan memasukkannya ke folder dataset
"""

source = kagglehub.dataset_download("uom190346a/food-ingredients-and-allergens")

# Define the destination path
destination_path = 'dataset'

# Move the dataset to the destination directory
shutil.copytree(source, destination_path)

print(f"Dataset downloaded and moved to {destination_path}")

"""#### Data Reading

melihat 5 data dari dataset untuk dianalisa
"""

df = pd.read_csv("/content/dataset/food_ingredients_and_allergens.csv")
df.head(5)

"""Melihat informasi dataset, seperti jumlah kolom, baris, dan tipe data"""

# Return information of dataframe
df.info()

"""Melakukan pengecekan dataset, apakah memiliki nilai null"""

# Check the null column
df.isnull().sum()

"""Mengecek dataset apakah memiliki data yang terduplikasi"""

# Check the duplicated column
df.duplicated().sum()

"""Melihat deskripsi dataset, seperti nilai yang sering muncul"""

df.describe(include="all")

"""#### Data Cleaning

Pada tahap ini fokus utamanya adalah untuk membersihkan dataset dari missing value, dan duplicated value
"""

# Fill the missing value using mode because dtype is object
for col in df.columns:
  if df[col].isnull().any():
    mode = df[col].mode()[0]
    df[col].fillna(mode, inplace=True)

# Check missing value again
df.isnull().sum()

# Delete duplicated data
df.drop_duplicates(inplace=True)
df.duplicated().sum()

# Check the total data
df.info()

"""#### Exploratory Data Analysis (EDA)

Tahap ini fokusnya adalah untuk melihat secara visual data-data yang ingin kita analisa sesuai dengan tujuan bisnis
"""

# Get allergens series
allergen_series = df["Allergens"].apply(lambda x: [i.strip() for i in x.split(",")])

# Convert the list of series data to flatten (2D to 1D)
allergen_flat = [allergen for sublist in allergen_series for allergen in sublist]

# Count the frequency each allergen
allergen_freq = Counter(allergen_flat)

# Convert to DataFrame
allergen_df = pd.DataFrame.from_dict(allergen_freq, orient='index', columns=['Frequency']).reset_index()
allergen_df.columns = ['Allergen', 'Frequency']
allergen_df

# Return the unique data from column Allergens
print("Total Allergens: ", len(allergen_df['Allergen'].unique()))
print("Allergens: ", allergen_df['Allergen'].unique())

plt.figure(figsize=[8, 5])
sns.barplot(data=allergen_df, x='Allergen', y='Frequency', palette='viridis')
plt.title('Frequency Allergen in Dataset')
plt.xlabel('Allergen')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Data Preparation

Pada tahap ini fokus utamanya untuk mempersiapkan data agar lebih siap untuk tahap modelling, selain itu pada tahap ini juga melakukan pembuatan dataframe cosine_sim (cosine similarity) untuk menyimpan kesamaan setiap data yang akan digunakan di tahap modelling
"""

# Inisialization using TfidfVectorizer
tf = TfidfVectorizer()

# Count Allergens from dataframe
tf.fit(df['Allergens'])

# Mapping array from index feature integer to name feature
tf.get_feature_names_out()

# Fit_transform to matrix
tfidf_matrix = tf.fit_transform(df['Allergens'])

# Return shape of tfidf_matrix
tfidf_matrix.shape

# Change vector to matrix using todense() function
tfidf_matrix.todense()

# Create dataframe to see tfidf_matrix
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=df['Food Product']
).sample(10, axis=1).sample(10, axis=0)

# Calculate cosine similarity on matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Create dataframe from variable cosine_sim
cosine_sim_df = pd.DataFrame(cosine_sim, index=df['Food Product'], columns=df['Food Product'])
print('Shape:', cosine_sim_df.shape)

# Return similarity matrix
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""### Modelling using Content Based Filtering

Pada tahap ini fokusnya adalah untuk membuat model AI untuk bisa memberikan rekomendasi makanan yang harus dihindari selain makanan yang pernah dimakan sesuai dengan kandungan Allergens
"""

# Create function model
def food_avoids(food_product, similarity_data=cosine_sim_df, items=df[['Food Product', 'Allergens']], k=10):
    """
    Avoids food products based on similarity of allergens.

    Args:
        food_product (str): The name of the food product to find avoids for.
        similarity_data (pd.DataFrame): The cosine similarity DataFrame.
        items (pd.DataFrame): DataFrame containing 'Food Product' and 'Allergens' columns.
        k (int): The number of avoids to return.

    Returns:
        pd.DataFrame: A DataFrame containing the top k avoids food products.
    """
    # Get the index of the food product in the items DataFrame
    try:
        index_val = items[items['Food Product'] == food_product].index[0]
    except IndexError:
        print(f"Food product '{food_product}' not found in the dataset.")
        return pd.DataFrame()  # Return an empty DataFrame if not found

    # Get the similarities for the given food product
    similarities = similarity_data.iloc[index_val].to_numpy()

    # Get the indices of the most similar items using argpartition
    # (excluding the item itself)
    index = similarities.argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(items.iloc[index_val]['Food Product'], errors='ignore')  # Drop the current item

    # Return the top k avoids
    # Create DataFrame with 'Food Product' as column
    avoids_df = pd.DataFrame(closest, columns=['Food Product'])
    # Merge on 'Food Product' column
    return avoids_df.merge(items, on='Food Product').head(k)

"""### Testing"""

# Return food product to test
food_product = 'Mushroom Risotto'
df[df['Food Product'].eq(food_product)].head(1)

# Return result from avoid food product based on allergen
food_product = 'Mushroom Risotto'
food_avoids = food_avoids(food_product)
food_avoids

"""### Evaluation

Melakukan evaluasi model dengan Precision@K, untuk mengukur proporsi item yang relevan di antara top-K rekomendasi
"""

def evaluate_recommendations(recommendations_df, ground_truth_df, k=10):
    """
    Evaluates the quality of food avoidance recommendations.

    Args:
        recommendations_df (pd.DataFrame): DataFrame of recommended avoids.  Must have columns 'Food Product' and 'Allergens'.
        ground_truth_df (pd.DataFrame): DataFrame of actual avoids (ground truth). Must have columns 'Food Product' and 'Allergens'.
        k (int): The number of recommendations to consider.

    Returns:
        dict: A dictionary containing evaluation metrics (e.g., precision@k, recall@k).
    """

    if not {'Food Product', 'Allergens'}.issubset(recommendations_df.columns):
        raise ValueError("recommendations_df must contain 'Food Product' and 'Allergens' columns.")

    if not {'Food Product', 'Allergens'}.issubset(ground_truth_df.columns):
        raise ValueError("ground_truth_df must contain 'Food Product' and 'Allergens' columns.")

    precision_at_k = 0  # Initialize precision
    total_relevant = 0

    # Iterate through recommendations
    for index, row in recommendations_df.iterrows():
        recommended_food = row['Food Product']
        recommended_allergens = row['Allergens']  # Get allergens for the recommended item

        # This should retrieve the true avoidances for a given food.
        true_avoidances = ground_truth_df[ground_truth_df["Food Product"] == recommended_food]["Allergens"].tolist()

        if true_avoidances:
           true_avoidances = true_avoidances[0]
           total_relevant += 1  # Increment count of actual avoids
           if recommended_allergens in true_avoidances:
              precision_at_k += 1

    # Calculate precision@k
    if total_relevant > 0:
        precision_at_k /= min(total_relevant, k)  # Divide by k or number of relevant items if less than k

    metrics = {'precision@k': precision_at_k}
    return metrics

ground_truth_data = {'Food Product': ['Chicken Shawarma', 'Chicken Shawarma', 'Chicken Fajitas', 'Mango Salsa', 'Mango Salsa', 'Lentil Curry', 'Green Smoothie', 'Sausage Pizza', 'Beef and Broccoli', '	Beef Burritos'], 'Allergens': ['Dairy' for _ in range(0, 10)]}
ground_truth_df = pd.DataFrame(ground_truth_data)

# Evaluate the recommendations
evaluation_results = evaluate_recommendations(food_avoids, ground_truth_df)
evaluation_results

"""Evaluasi menunjukkan hasil dari model sistem rekomendasi makanan yang harus dihindari adalah 10/10 = 1, yang artinya model sudah bekerja dengan baik"""